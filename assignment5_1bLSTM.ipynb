{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"assignment5_1bLSTM.ipynb","provenance":[{"file_id":"1cIWQHDi19rdkL1AGfJXCE_sCt7mA4CWp","timestamp":1622541972996},{"file_id":"1vxC-SgR6KxECk0p6oOEKtwnUCTWBdD6c","timestamp":1622541662867},{"file_id":"1VKtgzOo93-TLCX3IupT0spSkzCHHaCx0","timestamp":1622267138774}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQhOmQONjWFA","executionInfo":{"status":"ok","timestamp":1622605740503,"user_tz":-330,"elapsed":4332,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"3f0d2f3e-47ff-4a16-873a-d8b532263087"},"source":["import pandas as pd\n","!pip install pytreebank"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytreebank\n","  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n","Building wheels for collected packages: pytreebank\n","  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp37-none-any.whl size=37070 sha256=ed7ca7b4229813a496173f5f81e68697f99c0e1e4a5dd290e1c96b7521569e49\n","  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n","Successfully built pytreebank\n","Installing collected packages: pytreebank\n","Successfully installed pytreebank-0.2.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kwn5o9Koput0","executionInfo":{"status":"ok","timestamp":1622605744251,"user_tz":-330,"elapsed":3753,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["import torch"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ohcgUqdqH-m","executionInfo":{"status":"ok","timestamp":1622605744257,"user_tz":-330,"elapsed":10,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["import pytreebank\n","import sys\n","import os\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmLnp3S0vEZQ","executionInfo":{"status":"ok","timestamp":1622605750090,"user_tz":-330,"elapsed":5841,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["out_path = os.path.join(sys.path[0], 'sst_{}.txt')\n","dataset = pytreebank.load_sst('./raw_data')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qi05PKhPvJ_M","executionInfo":{"status":"ok","timestamp":1622605750103,"user_tz":-330,"elapsed":33,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["for category in ['train', 'test', 'dev']:\n","    with open(out_path.format(category), 'w') as outfile:\n","        for item in dataset[category]:\n","            outfile.write(\"__label__{}\\t{}\\n\".format(\n","                item.to_labeled_lines()[0][0] + 1,\n","                item.to_labeled_lines()[0][1]\n","            ))\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"xEFduBBUvQ5A","executionInfo":{"status":"ok","timestamp":1622605750104,"user_tz":-330,"elapsed":30,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["train_set=dataset['train']\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTiaTDNkwFXS","executionInfo":{"status":"ok","timestamp":1622605750105,"user_tz":-330,"elapsed":28,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["import pandas as pd"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"eudFJtZCwLki","executionInfo":{"status":"ok","timestamp":1622605750106,"user_tz":-330,"elapsed":27,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["df=pd.read_csv('./sst_train.txt',sep='\\t',header=None,names=['label','text'])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQRNJvvuFE-Z","executionInfo":{"status":"ok","timestamp":1622605750107,"user_tz":-330,"elapsed":27,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["test_set=pd.read_csv('./sst_test.txt',sep='\\t',header=None,names=['label','text'])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vKlC-YPGCv-","executionInfo":{"status":"ok","timestamp":1622605750108,"user_tz":-330,"elapsed":26,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["val_set=pd.read_csv('./sst_dev.txt',sep='\\t',header=None,names=['label','text'])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sj0NY25mx1Po","executionInfo":{"status":"ok","timestamp":1622605750112,"user_tz":-330,"elapsed":28,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["df['label']=df['label'].str.replace('__label__','')\n"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kGeIuc-HrtVc"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"JDIyapAa6Pjr","executionInfo":{"status":"ok","timestamp":1622605750722,"user_tz":-330,"elapsed":636,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["import random\n","import torch, torchtext\n","from torchtext import data"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kqZx2hG6e4Q","executionInfo":{"status":"ok","timestamp":1622605750724,"user_tz":-330,"elapsed":9,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"da40c7e1-d910-4218-f024-f9b3abe285f5"},"source":["# Manual Seed\n","SEED = 43\n","torch.manual_seed(SEED)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f7b8dcd2890>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"db3eiDVx6mKf","executionInfo":{"status":"ok","timestamp":1622605755600,"user_tz":-330,"elapsed":4881,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["#Tweet \n","Review_text= torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n","Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"-by1zHIV7LPI","executionInfo":{"status":"ok","timestamp":1622605755604,"user_tz":-330,"elapsed":37,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["fields = [('review',Review_text),('label',Label)]"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxmCFTgk797i","executionInfo":{"status":"ok","timestamp":1622605954929,"user_tz":-330,"elapsed":199357,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["train_example = [torchtext.legacy.data.Example.fromlist([df.text[i],df.label[i]], fields) for i in range(df.shape[0])] "],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Lj9XCy38OqE","executionInfo":{"status":"ok","timestamp":1622605954930,"user_tz":-330,"elapsed":23,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["train_set=torchtext.legacy.data.Dataset(train_example,fields)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"AwVLDJj1sHbF","executionInfo":{"status":"ok","timestamp":1622605954931,"user_tz":-330,"elapsed":21,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["test_set['label']=test_set['label'].str.replace('__label__','')\n","val_set['label']=val_set['label'].str.replace('__label__','')"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"65b27kErrp3s","executionInfo":{"status":"ok","timestamp":1622606032568,"user_tz":-330,"elapsed":77657,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["test_example = [torchtext.legacy.data.Example.fromlist([test_set.text[i],test_set.label[i]], fields) for i in range(test_set.shape[0])] \n","val_example = [torchtext.legacy.data.Example.fromlist([val_set.text[i],val_set.label[i]], fields) for i in range(val_set.shape[0])] "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kmCiKjzsjec","executionInfo":{"status":"ok","timestamp":1622606032569,"user_tz":-330,"elapsed":55,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["tst_set=torchtext.legacy.data.Dataset(test_example,fields)\n","vl_set=torchtext.legacy.data.Dataset(val_example,fields)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZVfuVj0pFiR","executionInfo":{"status":"ok","timestamp":1622606032570,"user_tz":-330,"elapsed":53,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"762d89a7-c2e2-45b3-accf-dcf8b072f589"},"source":["len(train_set),len(tst_set),len(vl_set)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8544, 2210, 1101)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"w_jtZLnaqjw8"},"source":["Looking at the distribution of different classes in the train_set, test_set and validation_set, I decided use the data augmentation techniques, like back translation, synonym replacement, random insertion, random deletion and random swap to make these datasets balanced.\n","Once that is done, pickling is done to store these datasets, rather than loading and creating them again and again.\n"]},{"cell_type":"code","metadata":{"id":"3mfQdgoAtTg8","executionInfo":{"status":"ok","timestamp":1622606032571,"user_tz":-330,"elapsed":48,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["Review_text.build_vocab(train_set)\n","Label.build_vocab(train_set)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zCPG8VrE9MKq","executionInfo":{"status":"ok","timestamp":1622606032573,"user_tz":-330,"elapsed":48,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"921e4c7a-38ef-484e-d104-6b4ef135d43b"},"source":["print('Size of input vocab : ', len(Review_text.vocab))\n","print('Size of label vocab : ', len(Label.vocab))\n","print('Top 10 words appreared repeatedly :', list(Review_text.vocab.freqs.most_common(10)))\n","print('Labels : ', Label.vocab.stoi)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Size of input vocab :  17165\n","Size of label vocab :  5\n","Top 10 words appreared repeatedly : [('.', 8041), (',', 7131), ('the', 6087), ('and', 4474), ('of', 4446), ('a', 4423), ('to', 3024), ('-', 2739), (\"'s\", 2544), ('is', 2540)]\n","Labels :  defaultdict(None, {'4': 0, '2': 1, '3': 2, '5': 3, '1': 4})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gBmMQQcX9SZk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622608142846,"user_tz":-330,"elapsed":394,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"fc0514c9-9709-465d-e48f-a7d75f1fb8c8"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":85}]},{"cell_type":"code","metadata":{"id":"OL5VTWKGuN0z","executionInfo":{"status":"ok","timestamp":1622608145504,"user_tz":-330,"elapsed":390,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["train_iterator = torchtext.legacy.data.BucketIterator(train_set, batch_size = 64, \n","                                                            sort_key = lambda x: len(x.review),\n","                                                            sort_within_batch=True, device = device)"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"V8_AHscmvsps","executionInfo":{"status":"ok","timestamp":1622608147738,"user_tz":-330,"elapsed":370,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["valid_iterator = torchtext.legacy.data.BucketIterator(vl_set, batch_size = 64, \n","                                                            sort_key = lambda x: len(x.review),\n","                                                            sort_within_batch=True, device = device)"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"l_NVSpoV-Uaj","executionInfo":{"status":"ok","timestamp":1622608149875,"user_tz":-330,"elapsed":391,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["import os, pickle\n","with open('tokenizer.pkl', 'wb') as tokens: \n","    #pickle.dump(Tweet.vocab.stoi, tokens)\n","    pickle.dump(Review_text.vocab.stoi,tokens)"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMkisCqRtfRJ","executionInfo":{"status":"ok","timestamp":1622606032577,"user_tz":-330,"elapsed":33,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":[""],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"fNQnNcH6-oZZ","executionInfo":{"status":"ok","timestamp":1622609371507,"user_tz":-330,"elapsed":345,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class classifier(nn.Module):\n","    \n","    # Define all the layers used in model\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n","        \n","        super(classifier,self).__init__()   \n","        self.embedding_dim=embedding_dim\n","        self.hidden_dim=hidden_dim\n","        self.output_dim=output_dim\n","        self.n_layers=n_layers       \n","        self.directions=2\n","        \n","        # Embedding layer\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        \n","        # GRU layer\n","        self.encoder = nn.LSTM(embedding_dim, \n","                           hidden_dim, \n","                           n_layers, \n","                           dropout=dropout,\n","                           batch_first=True,bidirectional=True)\n","        # try using nn.GRU or nn.RNN here and compare their performances\n","        # try bidirectional and compare their performances\n","        \n","        # Dense layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","        #adding another linear layer\n","        #self.fc2=nn.\n","        \n","    def forward(self, text, text_lengths):\n","        \n","        # text = [batch size, sent_length]\n","        embedded = self.embedding(text)\n","        # embedded = [batch size, sent_len, emb dim]\n","      \n","        # packed sequence\n","        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n","        packed_output, (hidden,cell) = self.encoder(packed_embedded)\n","        #hidden = [batch size, num layers * num directions,hid dim]\n","        #cell = [batch size, num layers * num directions,hid dim]\n","    \n","        # Hidden = [batch size, hid dim * num directions]\n","        dense_outputs = self.fc(hidden)     \n","        \n","        # Final activation function softmax\n","        output = F.softmax(dense_outputs[0], dim=1)\n","            \n","        return output"],"execution_count":130,"outputs":[]},{"cell_type":"code","metadata":{"id":"TFNWimMMAKya","executionInfo":{"status":"ok","timestamp":1622609376782,"user_tz":-330,"elapsed":1493,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["# Define hyperparameters\n","size_of_vocab=len(Review_text.vocab)\n","embedding_dim = 500\n","num_hidden_nodes = 200\n","num_output_nodes = 5\n","num_layers = 2\n","dropout = 0.2\n","\n","# Instantiate the model\n","model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRextCcAASGO","executionInfo":{"status":"ok","timestamp":1622609385278,"user_tz":-330,"elapsed":897,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"4ed6800a-691a-40b4-85b6-52976da20b1e"},"source":["print(model)\n","\n","#No. of trianable parameters\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","    \n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":132,"outputs":[{"output_type":"stream","text":["classifier(\n","  (embedding): Embedding(17165, 500)\n","  (encoder): LSTM(500, 200, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n","  (fc): Linear(in_features=200, out_features=5, bias=True)\n",")\n","The model has 10,669,905 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9sAGdpme3Pz","executionInfo":{"status":"ok","timestamp":1622609342544,"user_tz":-330,"elapsed":433,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"6bdc535e-5230-4171-892a-b68484676e89"},"source":["device"],"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":126}]},{"cell_type":"code","metadata":{"id":"EPK6b19HATLm","executionInfo":{"status":"ok","timestamp":1622609389272,"user_tz":-330,"elapsed":9,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["import torch.optim as optim\n","\n","# define optimizer and loss\n","optimizer = optim.Adam(model.parameters(), lr=2e-4)\n","criterion = nn.CrossEntropyLoss()\n","\n","# define metric\n","def binary_accuracy(preds, y):\n","    #round predictions to the closest integer\n","    _, predictions = torch.max(preds, 1)\n","    \n","    correct = (predictions == y).float() \n","    acc = correct.sum() / len(correct)\n","    return acc\n","\n","def cat_accuracy(preds,y):\n","    top_pred=preds.argmax(1,keepdim=True)\n","    correct=top_pred.eq(y.view_as(top_pred)).sum()\n","    acc=correct.float()/y.shape[0]\n","    return acc\n","    \n","# push to cuda if available\n","model = model.to(device)\n","criterion = criterion.to(device)"],"execution_count":133,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Ub6v1KwExbR","executionInfo":{"status":"ok","timestamp":1622609394804,"user_tz":-330,"elapsed":741,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["b=next(iter(train_iterator))\n","review,review_length=b.review\n","    \n"],"execution_count":134,"outputs":[]},{"cell_type":"code","metadata":{"id":"UadUnOfmBbuC","executionInfo":{"status":"ok","timestamp":1622608915928,"user_tz":-330,"elapsed":352,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["b=next(iter(valid_iterator))"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezT2-5rkGpue","executionInfo":{"status":"ok","timestamp":1622609398280,"user_tz":-330,"elapsed":6,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["predictions=model(review,review_length)\n","predictions.shape\n","\n","#optimizer.zero_grad()\n","loss = criterion(predictions, b.label)        \n","acc = cat_accuracy(predictions, b.label)   \n","#loss.backward()       \n","#optimizer.step()  "],"execution_count":135,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iuk1uki1-_xZ","executionInfo":{"status":"ok","timestamp":1622609402832,"user_tz":-330,"elapsed":362,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"0f7854d4-79f0-42d2-b0f9-4bece5065469"},"source":["loss.item()"],"execution_count":136,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.6107863187789917"]},"metadata":{"tags":[]},"execution_count":136}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CqAAfUelBoNl","executionInfo":{"status":"ok","timestamp":1622609406191,"user_tz":-330,"elapsed":355,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"52521c1a-f4b9-442b-a61c-63c5eaa9b2e6"},"source":["acc.item()"],"execution_count":137,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.15625"]},"metadata":{"tags":[]},"execution_count":137}]},{"cell_type":"code","metadata":{"id":"ZcPqZ_fp84sl","executionInfo":{"status":"ok","timestamp":1622607643245,"user_tz":-330,"elapsed":357,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":[" _, pred = torch.max(predictions, 1)"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8t9iWwqAify","executionInfo":{"status":"ok","timestamp":1622609412532,"user_tz":-330,"elapsed":394,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["def train(model, iterator, optimizer, criterion):\n","    \n","    # initialize every epoch \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    # set the model in training phase\n","    model.train()  \n","    \n","    for batch in iterator:\n","        \n","        # resets the gradients after every batch\n","        optimizer.zero_grad()   \n","        \n","        # retrieve text and no. of words\n","        #tweet, tweet_lengths = batch.tweet  \n","        review,review_length = batch.review\n","        \n","        # convert to 1D tensor\n","        #predictions = model(tweet, tweet_lengths).squeeze()  \n","        predictions=model(review,review_length)\n","        \n","        # compute the loss\n","        loss = criterion(predictions, batch.label)        \n","        \n","        # compute the categorical accuracy\n","        acc = cat_accuracy(predictions, batch.label)   \n","        \n","        # backpropage the loss and compute the gradients\n","        loss.backward()       \n","        \n","        # update the weights\n","        optimizer.step()      \n","        \n","        # loss and accuracy\n","        epoch_loss += loss.item()  \n","        epoch_acc += acc.item()    \n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":138,"outputs":[]},{"cell_type":"code","metadata":{"id":"LMBXHd5JAuX-","executionInfo":{"status":"ok","timestamp":1622609419635,"user_tz":-330,"elapsed":343,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["def evaluate(model, iterator, criterion):\n","    \n","    # initialize every epoch\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    # deactivating dropout layers\n","    model.eval()\n","    \n","    # deactivates autograd\n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","        \n","            # retrieve text and no. of words\n","            #tweet, tweet_lengths = batch.tweet\n","            review,review_length = batch.review\n","            \n","            # convert to 1d tensor\n","            predictions = model(review, review_length).squeeze()\n","            \n","            # compute loss and accuracy\n","            loss = criterion(predictions, batch.label)\n","            acc = cat_accuracy(predictions, batch.label)\n","            \n","            # keep track of loss and accuracy\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":139,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1gReGGkegAL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622606044114,"user_tz":-330,"elapsed":26,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"a7fe9712-f2a8-4744-f95e-9571165d5efe"},"source":["device"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"viVu0fdv0wJd","executionInfo":{"status":"ok","timestamp":1622609447053,"user_tz":-330,"elapsed":496,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["import matplotlib.pyplot as plt\n","from IPython import display\n","plt.style.use('seaborn-white')\n","import numpy as np"],"execution_count":140,"outputs":[]},{"cell_type":"code","metadata":{"id":"q7UPwN0KAvVq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622609764475,"user_tz":-330,"elapsed":104651,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"7324dae4-4c85-4ea2-dc1f-6d3be77cd89d"},"source":["N_EPOCHS = 50\n","best_valid_loss = float('inf')\n","global plot_iter, plot_loss_train, plot_loss_val\n","plot_iter = np.zeros((0))\n","plot_loss_train = np.zeros((0))\n","plot_loss_val = np.zeros((0))\n","plot_loss_test=np.zeros((0))\n","for epoch in range(N_EPOCHS):\n","     \n","    # train the model\n","    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n","    \n","    # evaluate the model\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n","    # evaluate the model on test data\n","    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","    # save the best model\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'saved_weights.pt')\n","    \n","    print(f'\\t epoch : {epoch} |\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')\n","    print(f'\\t Test. Loss: {test_loss:.3f} |  test. Acc: {test_acc*100:.2f}% \\n')\n","    plot_iter = np.append(plot_iter, [epoch])\n","    plot_loss_train = np.append(plot_loss_train, [train_loss])\n","    plot_loss_val = np.append(plot_loss_val, [valid_loss])\n","    plot_loss_test = np.append(plot_loss_test, [test_loss])\n"],"execution_count":142,"outputs":[{"output_type":"stream","text":["\t epoch : 0 |\tTrain Loss: 0.962 | Train Acc: 94.23%\n","\t Val. Loss: 1.563 |  Val. Acc: 32.96% \n","\n","\t Test. Loss: 1.560 |  test. Acc: 33.26% \n","\n","\t epoch : 1 |\tTrain Loss: 0.962 | Train Acc: 94.22%\n","\t Val. Loss: 1.564 |  Val. Acc: 32.10% \n","\n","\t Test. Loss: 1.565 |  test. Acc: 32.50% \n","\n","\t epoch : 2 |\tTrain Loss: 0.961 | Train Acc: 94.27%\n","\t Val. Loss: 1.565 |  Val. Acc: 32.45% \n","\n","\t Test. Loss: 1.562 |  test. Acc: 32.81% \n","\n","\t epoch : 3 |\tTrain Loss: 0.963 | Train Acc: 94.11%\n","\t Val. Loss: 1.566 |  Val. Acc: 32.18% \n","\n","\t Test. Loss: 1.570 |  test. Acc: 31.43% \n","\n","\t epoch : 4 |\tTrain Loss: 0.974 | Train Acc: 93.18%\n","\t Val. Loss: 1.576 |  Val. Acc: 31.48% \n","\n","\t Test. Loss: 1.580 |  test. Acc: 30.63% \n","\n","\t epoch : 5 |\tTrain Loss: 0.977 | Train Acc: 92.98%\n","\t Val. Loss: 1.570 |  Val. Acc: 31.74% \n","\n","\t Test. Loss: 1.576 |  test. Acc: 31.12% \n","\n","\t epoch : 6 |\tTrain Loss: 0.975 | Train Acc: 93.21%\n","\t Val. Loss: 1.560 |  Val. Acc: 33.13% \n","\n","\t Test. Loss: 1.565 |  test. Acc: 32.46% \n","\n","\t epoch : 7 |\tTrain Loss: 0.965 | Train Acc: 94.01%\n","\t Val. Loss: 1.566 |  Val. Acc: 32.35% \n","\n","\t Test. Loss: 1.552 |  test. Acc: 33.62% \n","\n","\t epoch : 8 |\tTrain Loss: 0.962 | Train Acc: 94.22%\n","\t Val. Loss: 1.574 |  Val. Acc: 31.66% \n","\n","\t Test. Loss: 1.564 |  test. Acc: 32.77% \n","\n","\t epoch : 9 |\tTrain Loss: 0.961 | Train Acc: 94.33%\n","\t Val. Loss: 1.568 |  Val. Acc: 32.01% \n","\n","\t Test. Loss: 1.569 |  test. Acc: 31.79% \n","\n","\t epoch : 10 |\tTrain Loss: 0.960 | Train Acc: 94.47%\n","\t Val. Loss: 1.564 |  Val. Acc: 32.70% \n","\n","\t Test. Loss: 1.565 |  test. Acc: 32.54% \n","\n","\t epoch : 11 |\tTrain Loss: 0.959 | Train Acc: 94.51%\n","\t Val. Loss: 1.564 |  Val. Acc: 32.79% \n","\n","\t Test. Loss: 1.564 |  test. Acc: 32.46% \n","\n","\t epoch : 12 |\tTrain Loss: 0.959 | Train Acc: 94.52%\n","\t Val. Loss: 1.564 |  Val. Acc: 32.88% \n","\n","\t Test. Loss: 1.564 |  test. Acc: 32.50% \n","\n","\t epoch : 13 |\tTrain Loss: 0.958 | Train Acc: 94.57%\n","\t Val. Loss: 1.573 |  Val. Acc: 31.92% \n","\n","\t Test. Loss: 1.565 |  test. Acc: 32.23% \n","\n","\t epoch : 14 |\tTrain Loss: 0.958 | Train Acc: 94.59%\n","\t Val. Loss: 1.565 |  Val. Acc: 32.45% \n","\n","\t Test. Loss: 1.565 |  test. Acc: 32.23% \n","\n","\t epoch : 15 |\tTrain Loss: 0.958 | Train Acc: 94.62%\n","\t Val. Loss: 1.565 |  Val. Acc: 32.62% \n","\n","\t Test. Loss: 1.561 |  test. Acc: 32.86% \n","\n","\t epoch : 16 |\tTrain Loss: 0.958 | Train Acc: 94.60%\n","\t Val. Loss: 1.564 |  Val. Acc: 33.21% \n","\n","\t Test. Loss: 1.557 |  test. Acc: 33.26% \n","\n","\t epoch : 17 |\tTrain Loss: 0.957 | Train Acc: 94.67%\n","\t Val. Loss: 1.569 |  Val. Acc: 32.35% \n","\n","\t Test. Loss: 1.562 |  test. Acc: 32.50% \n","\n","\t epoch : 18 |\tTrain Loss: 0.957 | Train Acc: 94.68%\n","\t Val. Loss: 1.563 |  Val. Acc: 32.87% \n","\n","\t Test. Loss: 1.560 |  test. Acc: 33.08% \n","\n","\t epoch : 19 |\tTrain Loss: 0.957 | Train Acc: 94.69%\n","\t Val. Loss: 1.563 |  Val. Acc: 32.87% \n","\n","\t Test. Loss: 1.565 |  test. Acc: 32.72% \n","\n","\t epoch : 20 |\tTrain Loss: 0.957 | Train Acc: 94.67%\n","\t Val. Loss: 1.572 |  Val. Acc: 31.65% \n","\n","\t Test. Loss: 1.571 |  test. Acc: 31.65% \n","\n","\t epoch : 21 |\tTrain Loss: 0.961 | Train Acc: 94.37%\n","\t Val. Loss: 1.563 |  Val. Acc: 32.87% \n","\n","\t Test. Loss: 1.568 |  test. Acc: 32.28% \n","\n","\t epoch : 22 |\tTrain Loss: 0.964 | Train Acc: 94.12%\n","\t Val. Loss: 1.578 |  Val. Acc: 31.06% \n","\n","\t Test. Loss: 1.569 |  test. Acc: 32.46% \n","\n","\t epoch : 23 |\tTrain Loss: 0.963 | Train Acc: 94.27%\n","\t Val. Loss: 1.563 |  Val. Acc: 32.53% \n","\n","\t Test. Loss: 1.573 |  test. Acc: 32.01% \n","\n","\t epoch : 24 |\tTrain Loss: 0.963 | Train Acc: 94.24%\n","\t Val. Loss: 1.560 |  Val. Acc: 33.13% \n","\n","\t Test. Loss: 1.571 |  test. Acc: 31.79% \n","\n","\t epoch : 25 |\tTrain Loss: 0.961 | Train Acc: 94.37%\n","\t Val. Loss: 1.557 |  Val. Acc: 33.66% \n","\n","\t Test. Loss: 1.563 |  test. Acc: 32.86% \n","\n","\t epoch : 26 |\tTrain Loss: 0.961 | Train Acc: 94.46%\n","\t Val. Loss: 1.559 |  Val. Acc: 33.49% \n","\n","\t Test. Loss: 1.575 |  test. Acc: 31.79% \n","\n","\t epoch : 27 |\tTrain Loss: 0.959 | Train Acc: 94.53%\n","\t Val. Loss: 1.578 |  Val. Acc: 31.66% \n","\n","\t Test. Loss: 1.569 |  test. Acc: 32.23% \n","\n","\t epoch : 28 |\tTrain Loss: 0.957 | Train Acc: 94.72%\n","\t Val. Loss: 1.563 |  Val. Acc: 32.88% \n","\n","\t Test. Loss: 1.566 |  test. Acc: 32.37% \n","\n","\t epoch : 29 |\tTrain Loss: 0.956 | Train Acc: 94.82%\n","\t Val. Loss: 1.571 |  Val. Acc: 31.66% \n","\n","\t Test. Loss: 1.570 |  test. Acc: 32.05% \n","\n","\t epoch : 30 |\tTrain Loss: 0.955 | Train Acc: 94.89%\n","\t Val. Loss: 1.570 |  Val. Acc: 32.18% \n","\n","\t Test. Loss: 1.567 |  test. Acc: 32.59% \n","\n","\t epoch : 31 |\tTrain Loss: 0.955 | Train Acc: 94.88%\n","\t Val. Loss: 1.573 |  Val. Acc: 31.75% \n","\n","\t Test. Loss: 1.559 |  test. Acc: 33.08% \n","\n","\t epoch : 32 |\tTrain Loss: 0.954 | Train Acc: 94.96%\n","\t Val. Loss: 1.563 |  Val. Acc: 33.22% \n","\n","\t Test. Loss: 1.564 |  test. Acc: 33.04% \n","\n","\t epoch : 33 |\tTrain Loss: 0.954 | Train Acc: 94.96%\n","\t Val. Loss: 1.565 |  Val. Acc: 32.62% \n","\n","\t Test. Loss: 1.560 |  test. Acc: 33.57% \n","\n","\t epoch : 34 |\tTrain Loss: 0.954 | Train Acc: 94.96%\n","\t Val. Loss: 1.557 |  Val. Acc: 33.91% \n","\n","\t Test. Loss: 1.566 |  test. Acc: 32.72% \n","\n","\t epoch : 35 |\tTrain Loss: 0.954 | Train Acc: 94.99%\n","\t Val. Loss: 1.558 |  Val. Acc: 33.74% \n","\n","\t Test. Loss: 1.559 |  test. Acc: 33.66% \n","\n","\t epoch : 36 |\tTrain Loss: 0.954 | Train Acc: 94.99%\n","\t Val. Loss: 1.560 |  Val. Acc: 32.97% \n","\n","\t Test. Loss: 1.566 |  test. Acc: 32.41% \n","\n","\t epoch : 37 |\tTrain Loss: 0.953 | Train Acc: 95.03%\n","\t Val. Loss: 1.567 |  Val. Acc: 32.36% \n","\n","\t Test. Loss: 1.560 |  test. Acc: 33.12% \n","\n","\t epoch : 38 |\tTrain Loss: 0.953 | Train Acc: 95.04%\n","\t Val. Loss: 1.559 |  Val. Acc: 33.23% \n","\n","\t Test. Loss: 1.560 |  test. Acc: 32.86% \n","\n","\t epoch : 39 |\tTrain Loss: 0.953 | Train Acc: 95.04%\n","\t Val. Loss: 1.555 |  Val. Acc: 33.48% \n","\n","\t Test. Loss: 1.558 |  test. Acc: 33.04% \n","\n","\t epoch : 40 |\tTrain Loss: 0.954 | Train Acc: 95.03%\n","\t Val. Loss: 1.551 |  Val. Acc: 34.78% \n","\n","\t Test. Loss: 1.565 |  test. Acc: 32.50% \n","\n","\t epoch : 41 |\tTrain Loss: 0.953 | Train Acc: 95.03%\n","\t Val. Loss: 1.556 |  Val. Acc: 34.08% \n","\n","\t Test. Loss: 1.566 |  test. Acc: 32.68% \n","\n","\t epoch : 42 |\tTrain Loss: 0.953 | Train Acc: 95.04%\n","\t Val. Loss: 1.561 |  Val. Acc: 32.61% \n","\n","\t Test. Loss: 1.567 |  test. Acc: 32.28% \n","\n","\t epoch : 43 |\tTrain Loss: 0.953 | Train Acc: 95.06%\n","\t Val. Loss: 1.555 |  Val. Acc: 33.22% \n","\n","\t Test. Loss: 1.555 |  test. Acc: 33.48% \n","\n","\t epoch : 44 |\tTrain Loss: 0.953 | Train Acc: 95.07%\n","\t Val. Loss: 1.574 |  Val. Acc: 31.83% \n","\n","\t Test. Loss: 1.569 |  test. Acc: 32.14% \n","\n","\t epoch : 45 |\tTrain Loss: 0.965 | Train Acc: 94.13%\n","\t Val. Loss: 1.559 |  Val. Acc: 33.23% \n","\n","\t Test. Loss: 1.559 |  test. Acc: 32.95% \n","\n","\t epoch : 46 |\tTrain Loss: 0.963 | Train Acc: 94.25%\n","\t Val. Loss: 1.566 |  Val. Acc: 32.52% \n","\n","\t Test. Loss: 1.566 |  test. Acc: 32.01% \n","\n","\t epoch : 47 |\tTrain Loss: 0.958 | Train Acc: 94.72%\n","\t Val. Loss: 1.567 |  Val. Acc: 31.66% \n","\n","\t Test. Loss: 1.571 |  test. Acc: 31.56% \n","\n","\t epoch : 48 |\tTrain Loss: 0.956 | Train Acc: 94.87%\n","\t Val. Loss: 1.557 |  Val. Acc: 33.22% \n","\n","\t Test. Loss: 1.576 |  test. Acc: 31.29% \n","\n","\t epoch : 49 |\tTrain Loss: 0.953 | Train Acc: 95.09%\n","\t Val. Loss: 1.558 |  Val. Acc: 33.56% \n","\n","\t Test. Loss: 1.581 |  test. Acc: 31.07% \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gU0-VTlt-DXn"},"source":["plt.plot(plot_iter, plot_loss_train, plot_loss_val)\n","display.clear_output(wait=True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbyzIHfkLH-R","executionInfo":{"status":"ok","timestamp":1622610012821,"user_tz":-330,"elapsed":373,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["test_iterator = torchtext.legacy.data.BucketIterator(tst_set, batch_size = 32, \n","                                                            sort_key = lambda x: len(x.review),\n","                                                            sort_within_batch=True, device = device)"],"execution_count":144,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZfqHYJ6QLTBv","executionInfo":{"status":"ok","timestamp":1622610015258,"user_tz":-330,"elapsed":429,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"4c0585a4-bac2-44ba-b491-f3f93371715a"},"source":["test_loss, test_acc = evaluate(model, test_iterator, criterion)\n","print(f'\\t Test. Loss: {test_loss:.3f} |  Test. Acc: {test_acc*100:.2f}% \\n')\n","print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')"],"execution_count":145,"outputs":[{"output_type":"stream","text":["\t Test. Loss: 1.574 |  Test. Acc: 31.74% \n","\n","\tTrain Loss: 0.953 | Train Acc: 95.09%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BXCGxks4AxT3","executionInfo":{"status":"ok","timestamp":1622606105819,"user_tz":-330,"elapsed":36,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":["#load weights and tokenizer\n","\n","path='./saved_weights.pt'\n","model.load_state_dict(torch.load(path));\n","model.eval();\n","tokenizer_file = open('./tokenizer.pkl', 'rb')\n","tokenizer = pickle.load(tokenizer_file)\n","\n","#inference \n","\n","import spacy\n","nlp = spacy.load('en')\n","\n","def classify_tweet(tweet):\n","    \n","    categories = {0: \"Positive\",1:\"Negative\", 2:\"Neutral\", 3:\"Very Positive\", 4:\"Very Negative\"}\n","    \n","    # tokenize the tweet \n","    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n","    # convert to integer sequence using predefined tokenizer dictionary\n","    indexed = [tokenizer[t] for t in tokenized]        \n","    # compute no. of words        \n","    length = [len(indexed)]\n","    # convert to tensor                                    \n","    tensor = torch.LongTensor(indexed).to(device)   \n","    # reshape in form of batch, no. of words           \n","    tensor = tensor.unsqueeze(1).T  \n","    # convert to tensor                          \n","    length_tensor = torch.LongTensor(length)\n","    # Get the model prediction                  \n","    prediction = model(tensor, length_tensor)\n","    print(prediction)\n","    print(prediction.max())\n","    print(categories)\n","\n","    _, pred = torch.max(prediction, 1) \n","    print (pred)\n","    print(pred.item())\n","    \n","    return categories[pred.item()]"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"C1mmb9YiHWOv","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1622606105820,"user_tz":-330,"elapsed":35,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}},"outputId":"ad50a500-bb2f-4511-ed14-f6c6243e9aad"},"source":["classify_tweet(\"never never never buy this product.\")"],"execution_count":46,"outputs":[{"output_type":"stream","text":["tensor([[2.5751e-05, 9.8939e-01, 9.6328e-03, 4.5416e-04, 4.9328e-04]],\n","       device='cuda:0', grad_fn=<SoftmaxBackward>)\n","tensor(0.9894, device='cuda:0', grad_fn=<MaxBackward1>)\n","{0: 'Positive', 1: 'Negative', 2: 'Neutral', 3: 'Very Positive', 4: 'Very Negative'}\n","tensor([1], device='cuda:0')\n","1\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Negative'"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"9XU_DlC1HY5T","executionInfo":{"status":"ok","timestamp":1622606105822,"user_tz":-330,"elapsed":32,"user":{"displayName":"Deepak Korpal","photoUrl":"","userId":"15567049575157029795"}}},"source":[""],"execution_count":46,"outputs":[]}]}